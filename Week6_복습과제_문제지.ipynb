{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca94bbc",
   "metadata": {},
   "source": [
    "\n",
    "# Euron Week 6 — 회귀(LinearRegression/다항회귀) 과제\n",
    "\n",
    "데이터셋: \n",
    "  - `fetch_california_housing()` (보스턴 데이터셋 사용 금지)\n",
    "  - 합성 코사인 데이터 (문항 C에서 생성)\n",
    "\n",
    "## 파트 구성\n",
    "- **A. LinearRegression & OLS**\n",
    "- **B. 회귀 평가 지표 & Scikit-Learn Scoring API**\n",
    "- **C. 다항 회귀 & 과소적합/과적합 (Bias–Variance)**\n",
    "\n",
    "> 유의: `load_boston()`는 삭제된 데이터셋입니다. **반드시** `fetch_california_housing()`을 사용하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28f88b",
   "metadata": {},
   "source": [
    "\n",
    "## A. LinearRegression & OLS\n",
    "\n",
    "### 캘리포니아 주택 가격 예측 (fit_intercept 비교) — ★★\n",
    "1) `fetch_california_housing()`으로 데이터셋(X, y)을 불러오고, `train_test_split(test_size=0.2, random_state=42)`로 분리하세요.  \n",
    "2) `LinearRegression(fit_intercept=True)`과 `LinearRegression(fit_intercept=False)`를 각각 학습하고, 테스트 세트 **R²**를 비교하세요.  \n",
    "3) 두 설정의 차이가 나는 이유를 **간단히** 서술하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b734aa9-1f6f-47f1-b0cd-71b652181a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1) 데이터 로드 & 분리\n",
    "data = fetch_california_housing()\n",
    "X, y = #답안#\n",
    "X_train, X_test, y_train, y_test = #답안#\n",
    "\n",
    "# 2) 두 모델 학습\n",
    "lr_t = ###답안###\n",
    "lr_f = ###답안###\n",
    "lr_t.fit(###답안###)\n",
    "lr_f.fit(###답안###)\n",
    "\n",
    "# 3) 성능 비교\n",
    "r2_t = r2_score(###답안###)\n",
    "r2_f = r2_score(###답안###)\n",
    "print(\"R2 (fit_intercept=True):\", r2_t)\n",
    "print(\"R2 (fit_intercept=False):\", r2_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a47a08-feb8-429c-890c-198ec6244860",
   "metadata": {},
   "source": [
    "\n",
    "3. 두 설정의 차이가 나는 이유를 간단히 서술하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa6703",
   "metadata": {},
   "source": [
    "\n",
    "## B. 회귀 평가 지표 & Scikit-Learn Scoring API (총 2문항)\n",
    "\n",
    "### B-1. 지표 함수 구현 & 비교 — ★★\n",
    "`mean_absolute_error, mean_squared_error, r2_score`를 이용해 MAE, MSE, RMSE, R²를 구현/출력하세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c29fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = lr_t.predict(X_test)\n",
    "\n",
    "mae = ###답안###\n",
    "mse = ###답안###\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = ###답안###\n",
    "\n",
    "print(mae, mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134d8d1",
   "metadata": {},
   "source": [
    "\n",
    "### B-2. `neg_mean_squared_error`의 의미 — ★\n",
    "1) `cross_val_score(..., scoring='neg_mean_squared_error')`로 5-Fold 결과를 얻고, **실제 MSE**로 변환해 평균/표준편차를 출력하세요.  \n",
    "2) 왜 `neg_` 접두사가 붙는지 한 줄로 설명하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9597c892",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LinearRegression(), X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "real_mse = ###답안###\n",
    "\n",
    "print(real_mse.mean(), real_mse.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840a106-a959-4077-961e-2c3a6f81c36b",
   "metadata": {},
   "source": [
    "B-2-2. 왜 neg_ 접두사가 붙는지 한 줄로 설명하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd3268",
   "metadata": {},
   "source": [
    "\n",
    "## C. 다항 회귀 & 과소적합/과적합\n",
    "\n",
    "### 코사인 데이터: Degree 1/4/15 비교 \n",
    "1) 구간 `[0, 1]`에서 **30개**의 X를 임의 샘플링하고, `y = cos(2πX) + N(0, 0.1)`로 타깃을 생성하세요.  \n",
    "2) `Pipeline([PolynomialFeatures(degree=d), LinearRegression()])`로 **degree=1,4,15** 모델을 학습하세요.  \n",
    "3) 각 모델에 대해 **10-Fold MSE**를 구해 평균을 출력하고, **Underfitting/Good Fit/Overfitting**을 판별하세요.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98fb240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "Xc = rng.rand(30, 1)\n",
    "yc = np.cos(2*np.pi*Xc).ravel() + rng.normal(0, 0.1, size=30)\n",
    "\n",
    "def cv_mse_for_degree(d):\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=d, include_bias=True)),\n",
    "                      ('lr', LinearRegression())])\n",
    "    scores = cross_val_score(model, Xc, yc, cv=KFold(n_splits=10, shuffle=True, random_state=0),\n",
    "                             scoring='neg_mean_squared_error')\n",
    "    return ###답안###\n",
    "\n",
    "for d in [###답안###]:     \n",
    "    print(d, cv_mse_for_degree(d)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
