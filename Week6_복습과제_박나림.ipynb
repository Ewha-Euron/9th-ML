{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aca94bbc",
      "metadata": {
        "id": "aca94bbc"
      },
      "source": [
        "\n",
        "# Euron Week 6 — 회귀(LinearRegression/다항회귀) 과제\n",
        "\n",
        "데이터셋:\n",
        "  - `fetch_california_housing()` (보스턴 데이터셋 사용 금지)\n",
        "  - 합성 코사인 데이터 (문항 C에서 생성)\n",
        "\n",
        "## 파트 구성\n",
        "- **A. LinearRegression & OLS**\n",
        "- **B. 회귀 평가 지표 & Scikit-Learn Scoring API**\n",
        "- **C. 다항 회귀 & 과소적합/과적합 (Bias–Variance)**\n",
        "\n",
        "> 유의: `load_boston()`는 삭제된 데이터셋입니다. **반드시** `fetch_california_housing()`을 사용하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f28f88b",
      "metadata": {
        "id": "4f28f88b"
      },
      "source": [
        "\n",
        "## A. LinearRegression & OLS\n",
        "\n",
        "### 캘리포니아 주택 가격 예측 (fit_intercept 비교) — ★★\n",
        "1) `fetch_california_housing()`으로 데이터셋(X, y)을 불러오고, `train_test_split(test_size=0.2, random_state=42)`로 분리하세요.  \n",
        "2) `LinearRegression(fit_intercept=True)`과 `LinearRegression(fit_intercept=False)`를 각각 학습하고, 테스트 세트 **R²**를 비교하세요.  \n",
        "3) 두 설정의 차이가 나는 이유를 **간단히** 서술하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9b734aa9-1f6f-47f1-b0cd-71b652181a5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b734aa9-1f6f-47f1-b0cd-71b652181a5a",
        "outputId": "c9f46c2e-871a-4cfc-efec-cb29f54b58bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 (fit_intercept=True): 0.5757877060324524\n",
            "R2 (fit_intercept=False): 0.5196561679229004\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1) 데이터 로드 & 분리\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2) 두 모델 학습\n",
        "lr_t = LinearRegression(fit_intercept=True)\n",
        "lr_f = LinearRegression(fit_intercept=False)\n",
        "lr_t.fit(X_train, y_train)\n",
        "lr_f.fit(X_train, y_train)\n",
        "\n",
        "# 3) 성능 비교\n",
        "r2_t = r2_score(y_test, lr_t.predict(X_test))\n",
        "r2_f = r2_score(y_test, lr_f.predict(X_test))\n",
        "print(\"R2 (fit_intercept=True):\", r2_t)\n",
        "print(\"R2 (fit_intercept=False):\", r2_f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18a47a08-feb8-429c-890c-198ec6244860",
      "metadata": {
        "id": "18a47a08-feb8-429c-890c-198ec6244860"
      },
      "source": [
        "3. 두 설정의 차이가 나는 이유를 간단히 서술하세요.\n",
        "\n",
        "데이터가 중심(0,0)에 맞춰 정규화되어 있지 않은데 절편을 제거하면 모델이 데이터를 잘 설명하지 못하기 때문에 성능 차이가 발생\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bfa6703",
      "metadata": {
        "id": "8bfa6703"
      },
      "source": [
        "\n",
        "## B. 회귀 평가 지표 & Scikit-Learn Scoring API (총 2문항)\n",
        "\n",
        "### B-1. 지표 함수 구현 & 비교 — ★★\n",
        "`mean_absolute_error, mean_squared_error, r2_score`를 이용해 MAE, MSE, RMSE, R²를 구현/출력하세요.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "a1c29fd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1c29fd0",
        "outputId": "f724da60-1558-4470-e331-ba666a669e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.533200130495698 0.5558915986952422 0.7455813830127749 0.5757877060324524\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
        "import numpy as np\n",
        "\n",
        "y_true = y_test\n",
        "y_pred = lr_t.predict(X_test)\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "mse = mean_squared_error(y_true, y_pred)\n",
        "rmse = np.sqrt(mse)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "\n",
        "print(mae, mse, rmse, r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f134d8d1",
      "metadata": {
        "id": "f134d8d1"
      },
      "source": [
        "\n",
        "### B-2. `neg_mean_squared_error`의 의미 — ★\n",
        "1) `cross_val_score(..., scoring='neg_mean_squared_error')`로 5-Fold 결과를 얻고, **실제 MSE**로 변환해 평균/표준편차를 출력하세요.  \n",
        "2) 왜 `neg_` 접두사가 붙는지 한 줄로 설명하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9597c892",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9597c892",
        "outputId": "a850ff24-f589-4c06-b70e-e41d72a9bc16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5582901717686811 0.06560199778303842\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "scores = cross_val_score(LinearRegression(), X, y, cv=5, scoring='neg_mean_squared_error')\n",
        "real_mse = -scores\n",
        "\n",
        "print(real_mse.mean(), real_mse.std())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e840a106-a959-4077-961e-2c3a6f81c36b",
      "metadata": {
        "id": "e840a106-a959-4077-961e-2c3a6f81c36b"
      },
      "source": [
        "B-2-2. 왜 neg_ 접두사가 붙는지 한 줄로 설명하세요.\n",
        "\n",
        "cross_val_score는 값이 클수록 좋은 점수 체계를 사용하기 때문에, 손실 함수(MSE)처럼 값이 작을수록 좋은 경우 음수로 반환하여 일관성을 유지하기 위해 neg_ 접두사가 붙는다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19dd3268",
      "metadata": {
        "id": "19dd3268"
      },
      "source": [
        "\n",
        "## C. 다항 회귀 & 과소적합/과적합\n",
        "\n",
        "### 코사인 데이터: Degree 1/4/15 비교\n",
        "1) 구간 `[0, 1]`에서 **30개**의 X를 임의 샘플링하고, `y = cos(2πX) + N(0, 0.1)`로 타깃을 생성하세요.  \n",
        "2) `Pipeline([PolynomialFeatures(degree=d), LinearRegression()])`로 **degree=1,4,15** 모델을 학습하세요.  \n",
        "3) 각 모델에 대해 **10-Fold MSE**를 구해 평균을 출력하고, **Underfitting/Good Fit/Overfitting**을 판별하세요.  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a98fb240",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a98fb240",
        "outputId": "af10c152-5b2a-4a96-9e29-4bdb3e308060"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.7226999447492073\n",
            "4 0.02001921890005632\n",
            "15 1290.6553915093937\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "\n",
        "rng = np.random.RandomState(0)\n",
        "Xc = rng.rand(30, 1)\n",
        "yc = np.cos(2*np.pi*Xc).ravel() + rng.normal(0, 0.1, size=30)\n",
        "\n",
        "def cv_mse_for_degree(d):\n",
        "    model = Pipeline([('poly', PolynomialFeatures(degree=d, include_bias=True)),\n",
        "                      ('lr', LinearRegression())])\n",
        "    scores = cross_val_score(model, Xc, yc, cv=KFold(n_splits=10, shuffle=True, random_state=0),\n",
        "                             scoring='neg_mean_squared_error')\n",
        "    return -scores.mean()\n",
        "\n",
        "for d in [1, 4, 15]:\n",
        "    print(d, cv_mse_for_degree(d))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:base] *",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}