{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca94bbc",
   "metadata": {},
   "source": [
    "\n",
    "# Euron Week 6 — 회귀(LinearRegression/다항회귀) 과제\n",
    "\n",
    "데이터셋: \n",
    "  - `fetch_california_housing()` (보스턴 데이터셋 사용 금지)\n",
    "  - 합성 코사인 데이터 (문항 C에서 생성)\n",
    "\n",
    "## 파트 구성\n",
    "- **A. LinearRegression & OLS**\n",
    "- **B. 회귀 평가 지표 & Scikit-Learn Scoring API**\n",
    "- **C. 다항 회귀 & 과소적합/과적합 (Bias–Variance)**\n",
    "\n",
    "> 유의: `load_boston()`는 삭제된 데이터셋입니다. **반드시** `fetch_california_housing()`을 사용하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f28f88b",
   "metadata": {},
   "source": [
    "\n",
    "## A. LinearRegression & OLS\n",
    "\n",
    "### 캘리포니아 주택 가격 예측 (fit_intercept 비교) — ★★\n",
    "1) `fetch_california_housing()`으로 데이터셋(X, y)을 불러오고, `train_test_split(test_size=0.2, random_state=42)`로 분리하세요.  \n",
    "2) `LinearRegression(fit_intercept=True)`과 `LinearRegression(fit_intercept=False)`를 각각 학습하고, 테스트 세트 **R²**를 비교하세요.  \n",
    "3) 두 설정의 차이가 나는 이유를 **간단히** 서술하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593a489e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
      "          37.88      , -122.23      ],\n",
      "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
      "          37.86      , -122.22      ],\n",
      "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
      "          37.85      , -122.24      ],\n",
      "       ...,\n",
      "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
      "          39.43      , -121.22      ],\n",
      "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
      "          39.43      , -121.32      ],\n",
      "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
      "          39.37      , -121.24      ]]), 'target': array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894]), 'frame': None, 'target_names': ['MedHouseVal'], 'feature_names': ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], 'DESCR': '.. _california_housing_dataset:\\n\\nCalifornia Housing dataset\\n--------------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 20640\\n\\n    :Number of Attributes: 8 numeric, predictive attributes and the target\\n\\n    :Attribute Information:\\n        - MedInc        median income in block group\\n        - HouseAge      median house age in block group\\n        - AveRooms      average number of rooms per household\\n        - AveBedrms     average number of bedrooms per household\\n        - Population    block group population\\n        - AveOccup      average number of household members\\n        - Latitude      block group latitude\\n        - Longitude     block group longitude\\n\\n    :Missing Attribute Values: None\\n\\nThis dataset was obtained from the StatLib repository.\\nhttps://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html\\n\\nThe target variable is the median house value for California districts,\\nexpressed in hundreds of thousands of dollars ($100,000).\\n\\nThis dataset was derived from the 1990 U.S. census, using one row per census\\nblock group. A block group is the smallest geographical unit for which the U.S.\\nCensus Bureau publishes sample data (a block group typically has a population\\nof 600 to 3,000 people).\\n\\nA household is a group of people residing within a home. Since the average\\nnumber of rooms and bedrooms in this dataset are provided per household, these\\ncolumns may take surprisingly large values for block groups with few households\\nand many empty houses, such as vacation resorts.\\n\\nIt can be downloaded/loaded using the\\n:func:`sklearn.datasets.fetch_california_housing` function.\\n\\n.. topic:: References\\n\\n    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,\\n      Statistics and Probability Letters, 33 (1997) 291-297\\n'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "data = fetch_california_housing()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b734aa9-1f6f-47f1-b0cd-71b652181a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 (fit_intercept=True): 0.5757877060324526\n",
      "R2 (fit_intercept=False): 0.5196561679229008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# 1) 데이터 로드 & 분리\n",
    "data = fetch_california_housing()\n",
    "X, y = data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2) 두 모델 학습\n",
    "lr_t = LinearRegression(fit_intercept=True)\n",
    "lr_f = LinearRegression(fit_intercept=False)\n",
    "lr_t.fit(X_train, y_train)\n",
    "lr_f.fit(X_train, y_train)\n",
    "\n",
    "# 3) 성능 비교\n",
    "r2_t = r2_score(y_test, lr_t.predict(X_test))\n",
    "r2_f = r2_score(y_test, lr_f.predict(X_test))\n",
    "print(\"R2 (fit_intercept=True):\", r2_t)\n",
    "print(\"R2 (fit_intercept=False):\", r2_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a47a08-feb8-429c-890c-198ec6244860",
   "metadata": {},
   "source": [
    "\n",
    "3. 두 설정의 차이가 나는 이유를 간단히 서술하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50fd145",
   "metadata": {},
   "source": [
    "fit_intercept=False를 하면 회귀 모델이 원점을 반드시 통과하도록 되므로 오차가 커져 R2가 낮아진다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfa6703",
   "metadata": {},
   "source": [
    "\n",
    "## B. 회귀 평가 지표 & Scikit-Learn Scoring API (총 2문항)\n",
    "\n",
    "### B-1. 지표 함수 구현 & 비교 — ★★\n",
    "`mean_absolute_error, mean_squared_error, r2_score`를 이용해 MAE, MSE, RMSE, R²를 구현/출력하세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c29fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5332001304956983 0.555891598695242 0.7455813830127748 0.5757877060324526\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_squared_log_error\n",
    "import numpy as np\n",
    "\n",
    "y_true = y_test\n",
    "y_pred = lr_t.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, lr_t.predict(X_test))\n",
    "mse = mean_squared_error(y_test, lr_t.predict(X_test))\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, lr_t.predict(X_test))\n",
    "print(mae, mse, rmse, r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f134d8d1",
   "metadata": {},
   "source": [
    "\n",
    "### B-2. `neg_mean_squared_error`의 의미 — ★\n",
    "1) `cross_val_score(..., scoring='neg_mean_squared_error')`로 5-Fold 결과를 얻고, **실제 MSE**로 변환해 평균/표준편차를 출력하세요.  \n",
    "2) 왜 `neg_` 접두사가 붙는지 한 줄로 설명하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9597c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5582901717686808 0.06560199778303905\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(LinearRegression(), X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "real_mse = -scores\n",
    "\n",
    "print(real_mse.mean(), real_mse.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840a106-a959-4077-961e-2c3a6f81c36b",
   "metadata": {},
   "source": [
    "B-2-2. 왜 neg_ 접두사가 붙는지 한 줄로 설명하세요.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4334bf0f",
   "metadata": {},
   "source": [
    "neg_mean_squared_error는 MSE에 마이너스를 붙인 값이므로 실제 MSE를 얻기 위해 다시 마이너스를 붙임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dd3268",
   "metadata": {},
   "source": [
    "\n",
    "## C. 다항 회귀 & 과소적합/과적합\n",
    "\n",
    "### 코사인 데이터: Degree 1/4/15 비교 \n",
    "1) 구간 `[0, 1]`에서 **30개**의 X를 임의 샘플링하고, `y = cos(2πX) + N(0, 0.1)`로 타깃을 생성하세요.  \n",
    "2) `Pipeline([PolynomialFeatures(degree=d), LinearRegression()])`로 **degree=1,4,15** 모델을 학습하세요.  \n",
    "3) 각 모델에 대해 **10-Fold MSE**를 구해 평균을 출력하고, **Underfitting/Good Fit/Overfitting**을 판별하세요.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a98fb240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.7226999447492073\n",
      "4 0.020019218900056472\n",
      "15 1290.3345849168654\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "Xc = rng.rand(30, 1)\n",
    "yc = np.cos(2*np.pi*Xc).ravel() + rng.normal(0, 0.1, size=30)\n",
    "\n",
    "def cv_mse_for_degree(d):\n",
    "    model = Pipeline([('poly', PolynomialFeatures(degree=d, include_bias=True)),\n",
    "                      ('lr', LinearRegression())])\n",
    "    scores = cross_val_score(model, Xc, yc, cv=KFold(n_splits=10, shuffle=True, random_state=0),\n",
    "                             scoring='neg_mean_squared_error')\n",
    "    return -scores.mean()\n",
    "\n",
    "for d in [1,4,15]:     \n",
    "    print(d, cv_mse_for_degree(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1efb5d",
   "metadata": {},
   "source": [
    "degree 1 -> underfitting  \n",
    "degree 4 -> good fit  \n",
    "degree 15 -> overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
